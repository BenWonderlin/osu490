{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from circleguard import KeylessCircleguard, ReplayDir\n",
    "from slider import Library\n",
    "\n",
    "from utils.replay_processing import filter_replay, validate_replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 12\n",
    "BATCH_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_PATH = \"../data/indices/base_index.csv\"\n",
    "BEATMAP_PATH = \"../data/beatmaps\"\n",
    "REPLAY_PATH = \"../data/replays/osr\"\n",
    "DB_PATH = \"../data/replays/osr/.circleguard.db\"\n",
    "SLIDER_PATH = \"../data/beatmaps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index and beatmaps\n",
    "\n",
    "index_df = pd.read_csv(INDEX_PATH, low_memory = False)\n",
    "beatmap_library = Library(BEATMAP_PATH)\n",
    "\n",
    "print(f\"Num. replays in index: {len(index_df)}\")\n",
    "print(f\"Num. of beatmaps in library: {len(beatmap_library.ids)}\")\n",
    "index_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_mod_str(replay):\n",
    "    mod_str = str(replay.mods)\n",
    "    res =   \"EZ\" * (\"EZ\" in mod_str) + \\\n",
    "            \"HD\" * (\"HD\" in mod_str) + \\\n",
    "            \"DT\" * (\"DT\" in mod_str or \"NC\" in mod_str) + \\\n",
    "            \"HR\" * (\"HR\" in mod_str)\n",
    "    if res == \"\":\n",
    "        res = \"NM\"\n",
    "    return res\n",
    "\n",
    "\n",
    "def build_valid_index_df(replay_dir, beatmap_library):\n",
    "\n",
    "    valid_idxs = []\n",
    "\n",
    "    for replay_idx, replay in enumerate(replay_dir):\n",
    "\n",
    "        beatmap = beatmap_library.lookup_by_md5(replay.beatmap_hash)\n",
    "\n",
    "        if filter_replay(replay, beatmap) == 0 and validate_replay(replay, beatmap) == 0:\n",
    "            valid_idxs.append([ replay_idx, get_clean_mod_str(replay), str(replay.path) ])\n",
    "\n",
    "    valid_index_df = pd.DataFrame(valid_idxs, columns = [\"replay_idx\", \"mods\", \"path\"])\n",
    "\n",
    "    return valid_index_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START_BATCH = 0\n",
    "\n",
    "# for batch_idx in range( START_BATCH, math.floor(len(index_df) / BATCH_SIZE) + 1 ):\n",
    "\n",
    "#     cg = KeylessCircleguard( \n",
    "#         db_path = DB_PATH,\n",
    "#         slider_dir = SLIDER_PATH,\n",
    "#         cache = True\n",
    "#     )\n",
    "    \n",
    "#     replay_dir = ReplayDir(REPLAY_PATH)\n",
    "#     cg.load_info(replay_dir)\n",
    "\n",
    "#     start_idx = batch_idx * BATCH_SIZE\n",
    "#     end_idx = min( (batch_idx + 1) * BATCH_SIZE, len(replay_dir))\n",
    "\n",
    "#     replay_dir.replays = replay_dir.replays[start_idx : end_idx]\n",
    "\n",
    "#     try:\n",
    "#         cg.load(replay_dir) # expensive\n",
    "#         valid_replay_df = build_valid_index_df(replay_dir, beatmap_library)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Bad batch: {batch_idx}\\n{e}\")\n",
    "#         continue\n",
    "\n",
    "#     valid_replay_df[\"replay_idx\"] = valid_replay_df[\"replay_idx\"].apply(lambda idx: idx + start_idx)\n",
    "#     valid_replay_df.to_csv(f\"valid_index_df_{batch_idx}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_index_df = pd.read_csv(\"data/valid_index.csv\")\n",
    "\n",
    "# X_train, X_test, _, _ = train_test_split(valid_index_df, valid_index_df[\"mods\"], test_size = 0.1, random_state = RANDOM_SEED, stratify = valid_index_df[\"mods\"])\n",
    "# X_train, X_val, _, _  = train_test_split(X_train, X_train[\"mods\"], test_size = 1/9, random_state = RANDOM_SEED, stratify = X_train[\"mods\"])\n",
    "\n",
    "# X_train.to_csv(\"train_index.csv\", index = False)\n",
    "# X_val.to_csv(\"val_index.csv\", index = False)\n",
    "# X_test.to_csv(\"test_index.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osu490",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
